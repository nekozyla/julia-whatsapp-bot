vamos adicionar um prefixo extr// messageHandlers.js
const { downloadMediaMessage, getContentType } = require('@whiskeysockets/baileys');
const { model } = require('./geminiClient'); 
const { saveSessionHistory, clearSession, getOrCreateChatForSession } = require('./sessionManager');
const { JULIA_INITIAL_GREETING, SPONTANEOUS_RESPONSE_CHANCE } = require('./config');
const { getTextFromMsg, sendJuliaError, convertAudioToWav } = require('./utils'); // Importa a nova função de áudio

// As funções de comando foram movidas para a pasta /commands.
// Este arquivo agora lida apenas com a lógica de CONVERSA.

async function handleSpontaneousResponse(sock, msg, chatSession, msgDetails) {
    const { sender, pushName, lastMessageText, isGroup } = msgDetails;
    if (isGroup && Math.random() < SPONTANEOUS_RESPONSE_CHANCE) {
        try {
            await sock.sendPresenceUpdate('composing', sender);
            const contextText = lastMessageText || "uma ação no grupo";
            let spontaneousPromptText = `Como uma participante de um grupo de WhatsApp chamada Julia, faça um comentário curto e pertinente ou divertido sobre a seguinte mensagem enviada por '${pushName}': "${contextText}". Se não tiver o que comentar, apenas diga algo amigável e espontâneo para o grupo, faça um comentario unico e de forma nenhuma faça varios, esta mensagem sera imediatamente enviada a conversa`;
            
            const result = await model.generateContent(spontaneousPromptText);
            const juliaSpontaneousText = result.response.text();
            
            if (juliaSpontaneousText) {
                await sock.sendMessage(sender, { text: juliaSpontaneousText }); 
            }
            return true; 
        } catch (error) { 
            console.error(`[Julia Espontânea] Erro:`, error);
        }
    }
    return false; 
}

async function handleContextualReply(sock, msg, chatSession, msgDetails) {
    const { sender, pushName, currentMessageText, quotedMsgInfo } = msgDetails;
    
    const quotedOriginalMessageType = getContentType(quotedMsgInfo?.message);
    const quotedText = getTextFromMsg(quotedMsgInfo); 
    
    let quotedAuthorDescriptor = "alguém";
    const quotedParticipantJid = msg.message.extendedTextMessage?.contextInfo?.participant;
    const currentUserJid = msg.key.participant || msg.key.remoteJid; 

    if (quotedMsgInfo?.key?.fromMe) { 
        quotedAuthorDescriptor = "você (Julia)";
    } else if (quotedParticipantJid) {
        if (quotedParticipantJid === currentUserJid) { 
            quotedAuthorDescriptor = pushName; 
        } else {
            quotedAuthorDescriptor = `o usuário ${quotedParticipantJid.split('@')[0]}`;
        }
    }
    
    let replyContextString;
    let specificInstructionForJulia;

    if (quotedOriginalMessageType === 'imageMessage') {
        const cleanQuotedCaption = quotedText ? quotedText.replace(/\s+/g, ' ').trim().substring(0, 150) : "";
        replyContextString = `(em resposta a uma IMAGEM enviada por ${quotedAuthorDescriptor}${cleanQuotedCaption ? ` com a legenda: "${cleanQuotedCaption}"` : ''}) se a legenda tiver algo como um pedido para fazer figurinha, diga apenas "use !help para ver todos os comandos`;
        specificInstructionForJulia = `Julia, minha mensagem é um comentário sobre a IMAGEM anterior de ${quotedAuthorDescriptor}. Por favor, responda ao meu comentário sobre essa imagem.`;
    } else if (quotedText?.trim()) {
        const cleanQuotedText = quotedText.replace(/\s+/g, ' ').trim().substring(0, 200); 
        replyContextString = `(em resposta a ${quotedAuthorDescriptor} que disse: "${cleanQuotedText}")`;
        specificInstructionForJulia = `Julia, por favor, comente sobre a minha resposta à mensagem anterior de ${quotedAuthorDescriptor}.`;
    } else {
        replyContextString = `(em resposta a uma mensagem anterior de ${quotedAuthorDescriptor} que não tinha texto)`;
        specificInstructionForJulia = `Julia, por favor, comente sobre a minha resposta, considerando que ela se refere a uma mensagem anterior de ${quotedAuthorDescriptor}.`;
    }
    
    const userMessageForGemini = `(${pushName}): "${currentMessageText}"\n\n${replyContextString}\n\n${specificInstructionForJulia} Mantenha o fio da conversa e o seu estilo.`;
    
    try {
        const result = await chatSession.sendMessage(userMessageForGemini);
        const juliaText = result.response.text();
        await sock.sendMessage(sender, { text: juliaText }, { quoted: msg }); 
        if (chatSession.history) await saveSessionHistory(sender, chatSession.history);
    } catch (error) { 
        await sendJuliaError(sock, sender, msg, error); 
    }
    return true;
}

async function handleStickerInterpretation(sock, msg, chatSession, msgDetails) {
    const { sender, pushName } = msgDetails;
    try {
        const stickerBuffer = await downloadMediaMessage(msg, 'buffer', {}, { logger: undefined });
        const stickerBase64 = stickerBuffer.toString('base64');
        const stickerMimeType = msg.message.stickerMessage.mimetype || 'image/webp';
        const promptParts = [
            { inlineData: { mimeType: stickerMimeType, data: stickerBase64 } },
            { text: `(Figurinha enviada por ${pushName}). Julia, considerando nossa conversa até agora, reaja a esta figurinha de forma curta e divertida.` }
        ];
        const result = await chatSession.sendMessage(promptParts);
        const juliaResponseToSticker = result.response.text();
        await sock.sendMessage(sender, { text: juliaResponseToSticker }, { quoted: msg }); 
        if (chatSession.history) await saveSessionHistory(sender, chatSession.history);
    } catch (error) { 
        await sendJuliaError(sock, sender, msg, error); 
    }
    return true;
}

async function handleImageInterpretation(sock, msg, chatSession, msgDetails) {
    const { sender, pushName, currentMessageText } = msgDetails; 
    try {
        const imageBuffer = await downloadMediaMessage(msg, 'buffer', {}, { logger: undefined });
        const imageBase64 = imageBuffer.toString('base64');
        const imageMimeType = msg.message.imageMessage.mimetype || 'image/jpeg';
        const promptParts = [
            { inlineData: { mimeType: imageMimeType, data: imageBase64 } },
            { text: `(Imagem enviada por ${pushName}${currentMessageText ? ` com a legenda: "${currentMessageText}"` : ''}). Julia, por favor, descreva ou comente sobre esta imagem.` }
        ];
        const result = await chatSession.sendMessage(promptParts);
        const juliaResponseToImage = result.response.text();
        await sock.sendMessage(sender, { text: juliaResponseToImage }, { quoted: msg }); 
        if (chatSession.history) await saveSessionHistory(sender, chatSession.history);
    } catch (error) { 
        await sendJuliaError(sock, sender, msg, error); 
    }
    return true; 
}

// --- NOVA FUNÇÃO ---
async function handleAudioInterpretation(sock, msg, chatSession, msgDetails) {
    const { sender, pushName } = msgDetails;
    console.log(`[Julia] Áudio recebido de ${pushName} no chat ${sender} para interpretação.`);

    try {
        // Baixa o áudio original
        const audioBuffer = await downloadMediaMessage(msg, 'buffer', {}, { logger: undefined });
        
        // Converte para um formato padrão (WAV) usando nossa nova função utilitária
        const wavBuffer = await convertAudioToWav(audioBuffer);
        const audioBase64 = wavBuffer.toString('base64');

        // Monta o prompt multimodal para o Gemini
        const promptParts = [
            { inlineData: { mimeType: 'audio/wav', data: audioBase64 } },
            { text: `(Áudio enviado por ${pushName}). Julia, ouça este áudio, entenda o que foi dito e responda de forma apropriada, mantendo o contexto da nossa conversa e o seu estilo.` }
        ];
        
        console.log(`[Julia] Enviando áudio de ${pushName} para o Gemini...`);
        const result = await chatSession.sendMessage(promptParts);
        const response = await result.response;
        const juliaText = response.text();
        console.log(`[Julia] Resposta do Gemini para o áudio: "${juliaText}"`);

        await sock.sendMessage(sender, { text: juliaText }, { quoted: msg });
        if (chatSession.history) await saveSessionHistory(sender, chatSession.history);

    } catch (error) {
        console.error(`[Julia] Erro ao interpretar áudio de ${pushName}:`, error);
        await sendJuliaError(sock, sender, msg, error);
    }
    return true;
}


async function handleTextMessage(sock, msg, chatSession, msgDetails, sessionManager) {
    const { sender, pushName, currentMessageText } = msgDetails;
    
    if (currentMessageText.toLowerCase() === '/start' || currentMessageText.toLowerCase() === '/iniciar') {
        console.log(`[Julia] Comando /start recebido do usuário: ${sender}. Recriando sessão.`);
        await sessionManager.clearSession(sender); 
        await getOrCreateChatForSession(sender);
        await sock.sendMessage(sender, { text: JULIA_INITIAL_GREETING }, { quoted: msg }); 
        return true;
    }
    if (currentMessageText.toLowerCase() === '/limpar') {
        await sessionManager.clearSession(sender);
        await sock.sendMessage(sender, { text: "Seu histórico de conversa comigo foi limpo! ✨" }, { quoted: msg }); 
        console.log(`[Julia] Histórico limpo para o usuário: ${sender}`);
        return true;
    }
    
    const userMessageForGemini = `(${pushName}): ${currentMessageText}`;
    try {
        const result = await chatSession.sendMessage(userMessageForGemini);
        const juliaText = result.response.text();
        
        await sock.sendMessage(sender, { text: juliaText }, { quoted: msg }); 
        if (chatSession.history) await saveSessionHistory(sender, chatSession.history);
    } catch (error) { 
        await sendJuliaError(sock, sender, msg, error); 
    }
    return true; 
}


module.exports = {
    handleSpontaneousResponse,
    handleContextualReply,
    handleStickerInterpretation,
    handleImageInterpretation, 
    handleAudioInterpretation, // Exporta a nova função de áudio
    handleTextMessage
};
